{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import RagEmbedding, RagLLM, QwenLLM\n",
    "from doc_parse import chunk, read_and_process_excel, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import chromadb\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSIST_DIRECTORY = \"./chroma_db/zhidu_db\"\n",
    "COLLECTION_NAME = \"zhidu_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [\"./data/zhidu_employee.pdf\", \"./data/zhidu_travel.pdf\"]\n",
    "excel_files = [\"./data/zhidu_detail.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_spliter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=128,\n",
    "    chunk_overlap=30,\n",
    "    separators=[\"\\n\\n\", \n",
    "                \"\\n\", \n",
    "                \".\", \n",
    "                \"\\uff0e\", \n",
    "                \"\\u3002\",\n",
    "                \",\",\n",
    "                \"\\uff0c\",\n",
    "                \"\\u3001'\"\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_data = []\n",
    "for pdf_file_name in pdf_files:\n",
    "    res = chunk(pdf_file_name, callback=logger)\n",
    "    for data in res:\n",
    "        content = data[\"content_with_weight\"]\n",
    "        if '<table>' not in content and len(content) > 200:\n",
    "            doc_data = doc_data + r_spliter.split_text(content)\n",
    "        else:\n",
    "            doc_data.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in doc_data:\n",
    "    print(len(i), \"=\"*10, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for excel_file_name in excel_files:\n",
    "    data = read_and_process_excel(excel_file_name)\n",
    "    df = pd.DataFrame(data[8:], columns=data[7])\n",
    "    data_excel = df.drop(columns=df.columns[11:17])\n",
    "    doc_data.append(data_excel.to_markdown(index=False).replace(' ', \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "documents = []\n",
    "\n",
    "for chunk in doc_data:\n",
    "    document = Document(\n",
    "        page_content=chunk,\n",
    "        metadata={\"source\": \"test\"})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cls = RagEmbedding(model_name=\"BAAI/bge-m3\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_db = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_cls,\n",
    "    persist_directory=PERSIST_DIRECTORY,  # 使用本地目录存储\n",
    "    collection_name=COLLECTION_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"迟到有什么规定？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_docs = embedding_db.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG问答流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = RagLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    你是企业员工助手，熟悉公司考勤和报销标准等规章制度，需要根据提供的上下文信息context来回答员工的提问。\\\n",
    "    请直接回答问题，如果上下文信息context没有和问题相关的信息，请直接回答[不知道,请咨询HR] \\\n",
    "    问题：{question} \n",
    "    \"{context}\"\n",
    "    回答：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义RAG问答流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_pipline(querys, k=3):\n",
    "    for query in querys:\n",
    "        \n",
    "        related_docs = embedding_db.similarity_search(query, k=k)\n",
    "        context = \"\\n\".join([f\"上下文{i+1}: {doc.page_content} \\n\" \\\n",
    "                         for i, doc in enumerate(related_docs)])\n",
    "        \n",
    "        print()\n",
    "        print(\"#\"*100)\n",
    "        print(f\"query: {query}\")\n",
    "        print(f\"context: {context}\")\n",
    "        llm_prompt = prompt_template.replace(\"{query}\", query).replace(\"{context}\", context)\n",
    "        response = llm(llm_prompt, stream=True)\n",
    "        print(f\"response: \")\n",
    "        \n",
    "        for chunk in response:\n",
    "            print(chunk.choices[0].text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_rag_pipline([\"加班有加班费吗？\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_rag_pipline([\"出差可以买意外险吗？需要自己购买吗？\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RagAs 评估框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = RagLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    你是企业员工助手，熟悉公司考勤和报销标准等规章制度，需要根据提供的上下文信息context来回答员工的提问。\\\n",
    "    请直接回答问题，如果上下文信息context没有和问题相关的信息，请直接回答[不知道,请咨询HR] \\\n",
    "    问题：{question} \n",
    "    \"{context}\"\n",
    "    回答：\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_pipline_without_stream(query, k=3):\n",
    "    related_docs = embedding_db.similarity_search(query, k=k)\n",
    "    context_list = [f\"上下文{i+1}: {doc.page_content} \\n\" \\\n",
    "                         for i, doc in enumerate(related_docs)]\n",
    "    context = \"\\n\".join(context_list)\n",
    "\n",
    "    llm_prompt = prompt_template.replace(\"{question}\", query).replace(\"{context}\", context)\n",
    "    response = llm(llm_prompt, stream=False)\n",
    "    return response, context_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建评估数据集\n",
    "- 问题\n",
    "- 标准答案\n",
    "- 上下文信息\n",
    "- 生成的答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"伙食补助费标准是什么?\",\n",
    "    \"出差可以买意外保险吗？需要自己购买吗\",\n",
    "]\n",
    "ground_truths = [\n",
    "    \"伙食补助费标准: 西藏、青海、新疆 120元/人、天 其他省份 100元/人、天\",\n",
    "    \"出差可以购买交通意外保险，由单位统一购买，不再重复购买\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "contexts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in questions:\n",
    "    response, context_list = run_rag_pipline_without_stream(query, k=3)\n",
    "    answers.append(response)\n",
    "    contexts.append(context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"user_input\": questions,\n",
    "    \"response\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truth\": ground_truths\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas import RunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_llm = QwenLLM()\n",
    "embedding_cls = RagEmbedding(model_name=\"BAAI/bge-m3\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunConfig(timeout=1200, log_tenacity = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [04:54<00:00, 36.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估结果：\n",
      "           user_input                                 retrieved_contexts  \\\n",
      "0         伙食补助费标准是什么?  [上下文1: <table><caption>伙食补助费参考以下标准：</caption>\\...   \n",
      "1  出差可以买意外保险吗？需要自己购买吗  [上下文1: 差旅费用标准\\n差旅费开支范围包括工作人员临时到常驻地以外地区公务出差所发生的...   \n",
      "\n",
      "                                            response  \\\n",
      "0      伙食补助费的标准如下：在西藏、青海、新疆地区，伙食补助费为120元/人、天；在其他省...   \n",
      "1  根据上下文信息，乘坐飞机、火车、轮船等交通工具的，每人次可以购买交通意外保险一份。由公司统一...   \n",
      "\n",
      "                                  reference  faithfulness  answer_relevancy  \\\n",
      "0  伙食补助费标准: 西藏、青海、新疆 120元/人、天 其他省份 100元/人、天           1.0          0.661572   \n",
      "1               出差可以购买交通意外保险，由单位统一购买，不再重复购买           1.0          0.000000   \n",
      "\n",
      "   context_recall  context_precision  \n",
      "0             1.0                1.0  \n",
      "1             1.0                1.0  \n"
     ]
    }
   ],
   "source": [
    "result = evaluate(\n",
    "    dataset = dataset,\n",
    "    llm = eval_llm,\n",
    "    embeddings = embedding_cls,\n",
    "    metrics=[faithfulness, answer_relevancy, context_recall, context_precision],\n",
    "    run_config=config,\n",
    "    raise_exceptions=True\n",
    ")\n",
    "\n",
    "df = result.to_pandas()\n",
    "print(\"评估结果：\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
